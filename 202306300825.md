---
tags: [performance, networking]
---

# Networking Fairness

Fairness in networking is defined as each connection getting equal share of link
bandwidth or the average rate of connection is roughly equal to the rate of
$\frac{R}{K}$ where $R$ is the transmission rate of the bottleneck link and $K$
is the number of connections. However, due to the asymmetric nature of end
points' window sizes and protocols, some processes may get more share on the
bandwidth than the other. For example, the session with less [Round-Trip Time (RTT)](202303292133.md)
can aquire bandwidth more quickly than those that with more RTT as it can open
the congestion window faster than the latter. Another example is
[UDP](202206151759.md), it has an advantage over [TCP](202206151232.md) in terms
of fairness due to no congestion control are implemented in the protocol, thus
no throttle will be done by the UDP in sacrificing the performance of the TCP
connections. If a process such as web browser could open up several parallel TCP
connections, it also has an advantage over those that don't as it could get more
link bandwidth allocated to itself.
