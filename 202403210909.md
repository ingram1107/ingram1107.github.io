---
tags: [hardware, caching, performance]
---

# Hardware Prefetching

Hardware prefetching, assuming in a single threaded sequential access
environment, is able to reduce the [L2 cache](202403191017.md) access time in
anticipation of the usage of consecutive memory regions. The processor should be
clever enough to recognise the size of strides (number of memory location
between beginnings of successive array elements) and doesn't fetch unnecessary
cache lines if the element size is smaller than the prefetch window. However,
hardware prefetching **can't cross page boundaries**. Even if it can, in the
event when the next page is not resident or valid, a page fault will be hit, and
it will take a toll on the program's performance.

Forced prefetch will be initiated when the element is known to be in L1d cache.

Despite the advantages, hardware prefetching may work in disadvantages in random
access environment which degrade the overall performance as the working set size
increases. This phenomenon scales worse proportionally to the randomness of the
access or the arrangement of the array's elements.
