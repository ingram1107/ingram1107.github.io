---
tags: [operating-system, memory]
---

# Non-Uniform Memory Access (NUMA)

NUMA is typically designed as a system with interconnected processors where each
has its own local [memory](202403132022.md). There is interconnect mechanism,
such as HyperTransport from AMD, that provides the access for processor that is
not directly connect to other remote RAM.

**Note**: Multiport RAM could be a solution theoretically, but it is too
expensive and complicated for NUMA system.

**Note**: [Clusters](202304251207.md) with high-speed networking is not NUMA.

NUMA system is usually deployed in **hypercube** topology. It limits the number
of nodes to $2^C$ where $C$ is the number of interconnect interfaces each node
has. Increasing the diameter, that is the maximum distance between two nodes,
arbitrarily can increase the size of the structure. Hypercubes have the smallest
diameter for all system with $2^n$ CPUs. Each hypercube has a diameter of $C$
which is the absolute minimum.

**Note**: The alternative topology is crossbars, but it comes at the cost of
increasing NUMA factor.

There are two ways of constructing a NUMA system. First, by connecting
commodity-like machine, like IBM x445, together with shared memory. However,
this introduces substantial NUMA factor. SGI approach, on the other hand,
deploys NUMAlink interconnect fabric that performs very fast and achieves low
latency. It is great for high-performance computing (HPC), especially when
Message Passing Interface (MPI) is used. Despite this fact, NUMA system tends to
connect a huge amount of machine with limited interconnect capability, causing
NUMA factor to be dynamic and might reach unacceptable levels depending on the
workload.

There are special cases like DSOs that shared among processors. In NUMA, it is
hard to implement mechanism to mirror DSO copies into all [CPU Caches](202403191017.md).
OS shouldn't migrate process or thread from one node to another since doing so
it will lose cache content. If it is forced to, the newly selected processor
shouldn't have higher memory access cost than the older processor unless there
is no choice for it. The way to handle it is either hope that the situation is
temporary and the process is migrated back to better-suited processor, or to
have the OS migrates the process's memory to physical pages closer to newly-used
processor. However, the latter solution is expensive and should be avoided if
possible since it has to copy huge amounts of memory, though not necessarily
done in one step. In the meantime, it will stop process so that the modification
to the old pages is correctly migrated.

Another problem that will be faced in NUMA system is the potential unequal
distribution memory usage by processes unless the application running are very
specific (in high-performance computing). The solution is to not allocate the
memory exclusively on local node, and have a strategy to stripe the memory. As a
side effect, it makes possible to freely migrate processes between processors as
on average memory access cost doesn't change. While for small NUMA factor
stripping is acceptable, but it is not optimal, with the drawback that the
overall system performance can sometimes be significantly reduced.
[Linux](202204081225.md) provides the alternative to allow custom memory
allocation rules for process.
